#!/bin/bash

function run_spark_shell() {
  spark_args=()
  jars=$deps_install_dir/$statsd_jar_file
  files=$deps_install_dir/$statsd_jar_file
  while [[ $# > 0 ]]; do
    case "$1" in
      --jars) jars="$jars,$2"
        shift
        ;;
      --files) files="$files,$2"
        shift
        ;; 
      *) spark_args+=("$1")
        [[ "$1" == *.jar ]] && flamegraph_title="$1"
        ;;
    esac
    shift
  done

  spark_cmd=(spark-shell-orig)    
  spark_cmd+=(--jars)
  spark_cmd+=("$jars")
  spark_cmd+=(--files)
  spark_cmd+=("$files")
  spark_cmd+=(--conf) 
  spark_cmd+=("spark.hadoop.validateOutputSpecs=false")
  spark_cmd+=(--conf)
  spark_cmd+=("spark.executor.extraJavaOptions=-javaagent:$deps_install_dir/$statsd_jar_file=server=${influxdb_host},port=${influxdb_port},reporter=InfluxDBReporter,database=profiler,username=profiler,password=profiler,prefix=sparkapp,tagMapping=spark,httpPort=$statsd_http_port")
  spark_cmd+=(${spark_args[@]})

  echo -e "[$(date +%FT%T)] Executing: ${spark_cmd[@]}"
  "${spark_cmd[@]}"
}

function generate_flamegraph() {
  pushd $graph_folder
  rm -rf stack_traces
  python $deps_install_dir/influxdb_dump.py -o $influxdb_host -r $influxdb_port -u profiler -p profiler -d profiler -t spark -e sparkapp -x stack_traces
  perl $install_dir/flamegraph.pl --title "$flamegraph_title" stack_traces/all_*.txt > /tmp/graph/flamegraph.svg
  rm -rf stack_traces
  echo -e "[$(date +%FT%T)] Created flamegraph: $(pwd)/flamegraph.svg"
  popd
}

graph_folder=/tmp/graph
deps_install_dir=/
statsd_jar_file=statsd-jvm-profiler-2.1.0-jar-with-dependencies.jar
influxdb_host=influxdb
influxdb_port=8086
statsd_http_port=5005
flamegraph_title="Spark Application"

run_spark_shell "$@"
generate_flamegraph